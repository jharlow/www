---
title: Write heavy, read scarce
date: '2025-04-16'
description: As AI exponentially increases how much we write, reading will become the in-demand skill.
tags:
  - blog
  - ai
  - reading
---

I believe that right now, one of the most undervalued skills in software engineers is the ability to read.

The first reason for thinking this is empirical. The best engineers I know are all big readers who devour serious texts like documentation, internal communication, and books voraciously.

The second is philosophical. I believe that long-form reading, and especially books, are where the best of human knowledge is stored. To not take reading seriously is therefore to seriously limit your knowledge potential.

However, I’m increasingly convinced that the best argument for reading is a predictive one; that the abundant resource will soon be writing, and the in-demand one reading.

I use predictive here very liberally, because in reality we’re already half way there. With AI, we have exponentially decreased the general cost of writing from what it once was. In doing so, LLMs have already fundamentally changed the split of reading to writing that the average engineer does. There are already engineers working today that are essentially read-only.

And that transformation looks likely to continue. As the models get faster, smarter, and cheaper we’ll use them for more. We’ll focus them on the tasks that take engineers the most time and produce the least value, and so we’ll focus them on writing tasks, since it (generally speaking) takes humans a lot longer to write something than to read it.

Of course, LLMs are also capable of reading in a slightly obtuse way, but while they can write an almost unlimited amount, most engineers continue to (probably correctly) gate-keep deployment of that code behind human review. Code review tools can help speed up review, but they're unlikely to replace it entirely until they become infallible because:

1. As with the purpose of human review, the person (or agent) who wrote the code is often least capable of reviewing it. If their thought patterns (or statical models) wrote the bug, they're less likely to catch them as someone/thing else.
2. Humans are risk averse and like to double check things before they chuck it into production.

So I think the obvious thing to do is get good at reading. In an attention economy, it's wise to have a lot of attention.
